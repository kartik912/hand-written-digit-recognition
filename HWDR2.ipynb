{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"3LBoovNqK8db","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697555671067,"user_tz":-330,"elapsed":5690,"user":{"displayName":"Kartik Yadav","userId":"01109628832264741342"}},"outputId":"c5dba741-c1e5-4f9f-810b-5ebfb2e55260"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install mnist"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"esSTrtHt76fR","executionInfo":{"status":"ok","timestamp":1697555676076,"user_tz":-330,"elapsed":5013,"user":{"displayName":"Kartik Yadav","userId":"01109628832264741342"}},"outputId":"508f0509-bf43-4871-c98e-219d87612f5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: mnist in /usr/local/lib/python3.10/dist-packages (0.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mnist) (1.23.5)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import mnist\n","from sklearn.model_selection import train_test_split\n","import cv2"],"metadata":{"id":"ZurPwp9s_CvU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load the MNIST dataset\n","train_images = mnist.train_images()\n","train_labels = mnist.train_labels()\n","test_images = mnist.test_images()\n","test_labels = mnist.test_labels()\n","\n","# Flatten and normalize the images\n","train_images = train_images.reshape(-1, 28*28) / 255.0\n","test_images = test_images.reshape(-1, 28*28) / 255.0\n","print(train_images[0])\n","# One-hot encode the labels\n","num_classes = 10\n","train_labels = np.eye(num_classes)[train_labels]\n","test_labels = np.eye(num_classes)[test_labels]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TO7yYbeo_HFB","executionInfo":{"status":"ok","timestamp":1697555677368,"user_tz":-330,"elapsed":1298,"user":{"displayName":"Kartik Yadav","userId":"01109628832264741342"}},"outputId":"51f281f6-42b4-44ac-8c95-d6443851aade"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n"," 0.49411765 0.53333333 0.68627451 0.10196078 0.65098039 1.\n"," 0.96862745 0.49803922 0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n"," 0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n"," 0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.19215686\n"," 0.93333333 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n"," 0.99215686 0.99215686 0.99215686 0.98431373 0.36470588 0.32156863\n"," 0.32156863 0.21960784 0.15294118 0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.07058824 0.85882353 0.99215686\n"," 0.99215686 0.99215686 0.99215686 0.99215686 0.77647059 0.71372549\n"," 0.96862745 0.94509804 0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n"," 0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.05490196 0.00392157 0.60392157 0.99215686 0.35294118\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.54509804 0.99215686 0.74509804 0.00784314 0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.04313725\n"," 0.74509804 0.99215686 0.2745098  0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.1372549  0.94509804\n"," 0.88235294 0.62745098 0.42352941 0.00392157 0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.31764706 0.94117647 0.99215686\n"," 0.99215686 0.46666667 0.09803922 0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n"," 0.58823529 0.10588235 0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.0627451  0.36470588 0.98823529 0.99215686 0.73333333\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.97647059 0.99215686 0.97647059 0.25098039 0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n"," 0.99215686 0.81176471 0.00784314 0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.15294118 0.58039216\n"," 0.89803922 0.99215686 0.99215686 0.99215686 0.98039216 0.71372549\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.09411765 0.44705882 0.86666667 0.99215686 0.99215686 0.99215686\n"," 0.99215686 0.78823529 0.30588235 0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n"," 0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.07058824 0.67058824\n"," 0.85882353 0.99215686 0.99215686 0.99215686 0.99215686 0.76470588\n"," 0.31372549 0.03529412 0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.21568627 0.6745098  0.88627451 0.99215686 0.99215686 0.99215686\n"," 0.99215686 0.95686275 0.52156863 0.04313725 0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.53333333 0.99215686\n"," 0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.         0.         0.\n"," 0.         0.         0.         0.        ]\n"]}]},{"cell_type":"code","source":["# Define a simple feedforward neural network\n","input_size = 28*28\n","hidden_size = 128\n","output_size = num_classes\n","learning_rate = 0.1\n","\n","# Initialize weights and biases\n","np.random.seed(0)\n","weights_input_hidden = np.random.randn(input_size, hidden_size)\n","biases_hidden = np.zeros(hidden_size)\n","weights_hidden_output = np.random.randn(hidden_size, output_size)\n","biases_output = np.zeros(output_size)\n","\n","# Softmax function\n","def softmax(x):\n","    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))  # Subtract the max for numerical stability\n","    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n","\n","# Training loop\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    for i in range(len(train_images)):\n","        # Forward pass\n","        input_layer = train_images[i]\n","        hidden_layer_input = np.dot(input_layer, weights_input_hidden) + biases_hidden\n","        hidden_layer_output = 1 / (1 + np.exp(-hidden_layer_input))  # Sigmoid activation\n","        output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + biases_output\n","        output_layer_output = softmax(output_layer_input)\n","\n","        # Calculate loss (cross-entropy)\n","        loss = -np.sum(train_labels[i] * np.log(output_layer_output))\n","\n","        # Backpropagation\n","        output_error = output_layer_output - train_labels[i]\n","        hidden_error = np.dot(output_error, weights_hidden_output.T)\n","        hidden_delta = hidden_error * hidden_layer_output * (1 - hidden_layer_output)\n","        weights_hidden_output -= learning_rate * np.outer(hidden_layer_output, output_error)\n","        biases_output -= learning_rate * output_error\n","        weights_input_hidden -= learning_rate * np.outer(input_layer, hidden_delta)\n","        biases_hidden -= learning_rate * hidden_delta\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss}\")\n","\n","# Testing\n","correct = 0\n","for i in range(len(test_images)):\n","    input_layer = test_images[i]\n","    hidden_layer_input = np.dot(input_layer, weights_input_hidden) + biases_hidden\n","    hidden_layer_output = 1 / (1 + np.exp(-hidden_layer_input))  # Sigmoid activation\n","    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + biases_output\n","    output_layer_output = softmax(output_layer_input)\n","    prediction = np.argmax(output_layer_output)\n","    if prediction == np.argmax(test_labels[i]):\n","        correct += 1\n","\n","accuracy = correct / len(test_images) * 100\n","print(f\"Test Accuracy: {accuracy:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XpI5rlYX7j9W","executionInfo":{"status":"ok","timestamp":1697556037367,"user_tz":-330,"elapsed":360004,"user":{"displayName":"Kartik Yadav","userId":"01109628832264741342"}},"outputId":"b6818cbc-15f2-4058-c8cf-82ae717d191e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Loss: 0.004516028464485289\n","Epoch 2/10, Loss: 0.043812574829080964\n","Epoch 3/10, Loss: 0.0031264021158887603\n","Epoch 4/10, Loss: 0.0014930148449012887\n","Epoch 5/10, Loss: 4.117821746785725e-05\n","Epoch 6/10, Loss: 0.0020665994303881033\n","Epoch 7/10, Loss: 0.00023835802309048236\n","Epoch 8/10, Loss: 0.00013163160594177454\n","Epoch 9/10, Loss: 2.015382771732109e-06\n","Epoch 10/10, Loss: 2.761276110758433e-05\n","Test Accuracy: 95.92%\n"]}]},{"cell_type":"code","source":["image = cv2.imread('/content/drive/MyDrive/hand digit digit recog/input image/six.PNG', cv2.IMREAD_GRAYSCALE)\n","resized_image = cv2.resize(image, (28, 28))\n","normalized_image = resized_image / 255.0\n","\n","# input_image = image.reshape(-1, 28*28) / 255.0\n","flattened_image = normalized_image.reshape(1, -1)\n","flattened_image[flattened_image >= 1] = 0"],"metadata":{"id":"O6D4PqGLKwXk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_layer = flattened_image\n","hidden_layer_input = np.dot(input_layer, weights_input_hidden) + biases_hidden\n","hidden_layer_output = 1 / (1 + np.exp(-hidden_layer_input))  # Sigmoid activation\n","output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + biases_output\n","output_layer_output = softmax(output_layer_input)\n","prediction = np.argmax(output_layer_output)\n","\n","print(prediction)"],"metadata":{"id":"PbIUYIDx73Y0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697556885773,"user_tz":-330,"elapsed":5,"user":{"displayName":"Kartik Yadav","userId":"01109628832264741342"}},"outputId":"5c974d51-8ecb-4ef0-8500-5b8e27811e6c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["5\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"uBVczSxiRTSL"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}