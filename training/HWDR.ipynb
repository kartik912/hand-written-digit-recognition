{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTING LIBRARIES"
      ],
      "metadata": {
        "id": "nBC_vFktCY5n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uhNzOS8ht7iG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DOWNLOADING DATASET"
      ],
      "metadata": {
        "id": "RDhS9FFJCdAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "PdBi6tAhumA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a112fdac-32f8-4c11-d6c2-e0ed48fea32b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# checking if dataset is balanced or not"
      ],
      "metadata": {
        "id": "Fz5JoxpNydzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Count the occurrences of each label in the training set\n",
        "unique_train_labels, train_counts = np.unique(train_labels, return_counts=True)\n",
        "train_label_counts = dict(zip(unique_train_labels, train_counts))\n",
        "\n",
        "# Count the occurrences of each label in the test set\n",
        "unique_test_labels, test_counts = np.unique(test_labels, return_counts=True)\n",
        "test_label_counts = dict(zip(unique_test_labels, test_counts))\n",
        "\n",
        "# Display the counts\n",
        "print(\"Training set label counts:\")\n",
        "for label, count in train_label_counts.items():\n",
        "    print(f\"Label {label}: {count}\")\n",
        "\n",
        "print(\"\\nTest set label counts:\")\n",
        "for label, count in test_label_counts.items():\n",
        "    print(f\"Label {label}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HyawwWPkyUNf",
        "outputId": "307546d5-cc0d-41c4-d164-94bdfbf8e571"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set label counts:\n",
            "Label 0: 5923\n",
            "Label 1: 6742\n",
            "Label 2: 5958\n",
            "Label 3: 6131\n",
            "Label 4: 5842\n",
            "Label 5: 5421\n",
            "Label 6: 5918\n",
            "Label 7: 6265\n",
            "Label 8: 5851\n",
            "Label 9: 5949\n",
            "\n",
            "Test set label counts:\n",
            "Label 0: 980\n",
            "Label 1: 1135\n",
            "Label 2: 1032\n",
            "Label 3: 1010\n",
            "Label 4: 982\n",
            "Label 5: 892\n",
            "Label 6: 958\n",
            "Label 7: 1028\n",
            "Label 8: 974\n",
            "Label 9: 1009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RESHAPING THE IMAGES"
      ],
      "metadata": {
        "id": "8_wGIubiNMMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_images.reshape(-1, 28*28) / 255.0\n",
        "test_images = test_images.reshape(-1, 28*28) / 255.0\n",
        "num_classes = 10\n",
        "train_labels = np.eye(num_classes)[train_labels]\n",
        "test_labels = np.eye(num_classes)[test_labels]"
      ],
      "metadata": {
        "id": "7qKePHvQuo-v",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OLD code"
      ],
      "metadata": {
        "id": "U84QdXPM01oU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple feedforward neural network\n",
        "input_size = 28*28\n",
        "hidden_size = 128\n",
        "output_size = num_classes\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Initialize weights and biases\n",
        "np.random.seed(0)\n",
        "weights_input_hidden = np.random.randn(input_size, hidden_size)\n",
        "biases_hidden = np.zeros(hidden_size)\n",
        "weights_hidden_output = np.random.randn(hidden_size, output_size)\n",
        "biases_output = np.zeros(output_size)\n",
        "\n",
        "# Softmax function\n",
        "def softmax(x):\n",
        "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))  # Subtract the max for numerical stability\n",
        "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    all_predictions = []\n",
        "    all_true_labels = []\n",
        "\n",
        "    for i in range(len(train_images)):\n",
        "        # Forward pass\n",
        "        input_layer = train_images[i]\n",
        "        hidden_layer_input = np.dot(input_layer, weights_input_hidden) + biases_hidden\n",
        "        hidden_layer_output = 1 / (1 + np.exp(-hidden_layer_input))  # Sigmoid activation\n",
        "        output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + biases_output\n",
        "        output_layer_output = softmax(output_layer_input)\n",
        "\n",
        "        # Calculate loss (cross-entropy)\n",
        "        loss = -np.sum(train_labels[i] * np.log(output_layer_output))\n",
        "\n",
        "        # Backpropagation\n",
        "        output_error = output_layer_output - train_labels[i]\n",
        "        hidden_error = np.dot(output_error, weights_hidden_output.T)\n",
        "        hidden_delta = hidden_error * hidden_layer_output * (1 - hidden_layer_output)\n",
        "        weights_hidden_output -= learning_rate * np.outer(hidden_layer_output, output_error)\n",
        "        biases_output -= learning_rate * output_error\n",
        "        weights_input_hidden -= learning_rate * np.outer(input_layer, hidden_delta)\n",
        "        biases_hidden -= learning_rate * hidden_delta\n",
        "\n",
        "        all_predictions.append(np.argmax(output_layer_output))\n",
        "        all_true_labels.append(np.argmax(train_labels[i]))\n",
        "\n",
        "    accuracy = accuracy_score(all_true_labels, all_predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_true_labels, all_predictions, average='macro')\n",
        "    cm = confusion_matrix(all_true_labels, all_predictions)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss/len(train_images):.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "# Testing\n",
        "all_test_predictions = []\n",
        "all_test_true_labels = []\n",
        "\n",
        "for i in range(len(test_images)):\n",
        "    input_layer = test_images[i]\n",
        "    hidden_layer_input = np.dot(input_layer, weights_input_hidden) + biases_hidden\n",
        "    hidden_layer_output = 1 / (1 + np.exp(-hidden_layer_input))  # Sigmoid activation\n",
        "    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + biases_output\n",
        "    output_layer_output = softmax(output_layer_input)\n",
        "    prediction = np.argmax(output_layer_output)\n",
        "    all_test_predictions.append(prediction)\n",
        "    all_test_true_labels.append(np.argmax(test_labels[i]))\n",
        "\n",
        "accuracy = accuracy_score(all_test_true_labels, all_test_predictions)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(all_test_true_labels, all_test_predictions, average='macro')\n",
        "cm = confusion_matrix(all_test_true_labels, all_test_predictions)\n",
        "\n",
        "print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Test Precision: {precision:.4f}, Test Recall: {recall:.4f}, Test F1 Score: {f1:.4f}\")\n",
        "print(\"Test Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "8FgQyJ7kuA6t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd9cb8d1-e537-4064-a954-46824800b68c",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.0000, Accuracy: 0.8829, Precision: 0.8815, Recall: 0.8815, F1 Score: 0.8815\n",
            "Confusion Matrix:\n",
            "[[5549    2   50   32   10   93   70   25   67   25]\n",
            " [   1 6437   56   51    7   26   17   33   94   20]\n",
            " [  57   60 5177  149   89   33  120   82  163   28]\n",
            " [  30   35  187 5189    9  272   32   90  216   71]\n",
            " [  17   18   59   10 5156   29   80   57   60  356]\n",
            " [  96   25   43  274   60 4523  126   34  162   78]\n",
            " [  79   25   93   18   85  108 5432   13   54   11]\n",
            " [  27   48   89   64   67   39    6 5649   38  238]\n",
            " [  53   90  136  242   51  167   63   26 4890  133]\n",
            " [  38   24   27   94  342   73    8  238  132 4973]]\n",
            "Epoch 2/10, Loss: 0.0000, Accuracy: 0.9379, Precision: 0.9372, Recall: 0.9372, F1 Score: 0.9372\n",
            "Confusion Matrix:\n",
            "[[5732    4   36    7    4   38   43    9   36   14]\n",
            " [   1 6581   31   29   12    4    9   13   44   18]\n",
            " [  39   29 5574   71   45   14   39   56   73   18]\n",
            " [   9   25   94 5601    6  162   16   42  134   42]\n",
            " [   8   16   38    4 5470   13   46   33   23  191]\n",
            " [  46   11   11  154   22 4963   64   21   86   43]\n",
            " [  48    7   45    7   39   65 5656    3   47    1]\n",
            " [   7   27   49   38   41   19    3 5939   19  123]\n",
            " [  26   50   62  127   27   75   47   14 5338   85]\n",
            " [  20    9   10   55  187   50    4  125   68 5421]]\n",
            "Epoch 3/10, Loss: 0.0000, Accuracy: 0.9544, Precision: 0.9538, Recall: 0.9539, F1 Score: 0.9538\n",
            "Confusion Matrix:\n",
            "[[5781    1   19    5    9   27   27   11   32   11]\n",
            " [   1 6610   27   18   12    0    7   18   35   14]\n",
            " [  24   22 5698   63   22   11   18   39   52    9]\n",
            " [   9   17   80 5741    2  110    7   38   92   35]\n",
            " [   9    7   15    5 5568    8   30   23   18  159]\n",
            " [  34   10    6  102   13 5091   59    8   54   44]\n",
            " [  35    8   20    4   23   48 5750    1   27    2]\n",
            " [   8   22   42   20   30   14    3 6034   17   75]\n",
            " [  22   36   44   99   20   64   31   13 5473   49]\n",
            " [  21   12    8   50  159   36    2   92   54 5515]]\n",
            "Epoch 4/10, Loss: 0.0000, Accuracy: 0.9626, Precision: 0.9622, Recall: 0.9622, F1 Score: 0.9622\n",
            "Confusion Matrix:\n",
            "[[5808    2   19    4    4   22   19    5   29   11]\n",
            " [   3 6636   23   10    9    4    7   15   25   10]\n",
            " [  24   21 5723   53   10   10   17   41   46   13]\n",
            " [   7   13   60 5816    5   93    5   33   70   29]\n",
            " [   7    9   17    1 5631    7   22   16   18  114]\n",
            " [  23    7   12   83   12 5158   38    7   43   38]\n",
            " [  25    7   17    2   18   31 5789    1   27    1]\n",
            " [   4   21   39   32   22    6    2 6048   15   76]\n",
            " [  16   28   39   72   12   50   33   12 5544   45]\n",
            " [  13   10   10   43  137   26    3   67   40 5600]]\n",
            "Epoch 5/10, Loss: 0.0000, Accuracy: 0.9689, Precision: 0.9686, Recall: 0.9686, F1 Score: 0.9686\n",
            "Confusion Matrix:\n",
            "[[5841    1   13    6    4   11   18    2   23    4]\n",
            " [   0 6645   21   10    9    0    4   18   26    9]\n",
            " [  12   12 5792   29   11    4   15   30   44    9]\n",
            " [   6   11   51 5855    3   78    5   28   62   32]\n",
            " [   7   13   17    5 5654    8   21   17   12   88]\n",
            " [  14    4    4   77    4 5208   30    5   48   27]\n",
            " [  22    6   11    2   15   36 5802    0   23    1]\n",
            " [   5   17   33   21   18    5    0 6090   11   65]\n",
            " [  14   28   29   53   16   42   28   16 5584   41]\n",
            " [  14   12    6   36   98   28    2   56   36 5661]]\n",
            "Epoch 6/10, Loss: 0.0000, Accuracy: 0.9734, Precision: 0.9732, Recall: 0.9732, F1 Score: 0.9732\n",
            "Confusion Matrix:\n",
            "[[5853    1   11    4    4    6   17    5   17    5]\n",
            " [   1 6658   16   13    7    1    5   14   19    8]\n",
            " [  20   14 5805   29   11    6    9   30   26    8]\n",
            " [   6    9   47 5888    3   61    2   22   68   25]\n",
            " [   4   11    9    2 5678    2   20   15   14   87]\n",
            " [  13    5    5   60    5 5240   29    5   42   17]\n",
            " [  20    3    7    3   14   26 5827    0   17    1]\n",
            " [   5   15   24   22   17    2    0 6124    6   50]\n",
            " [  13   24   29   57   10   42   23    9 5603   41]\n",
            " [   7    6    3   26   80   18    1   48   30 5730]]\n",
            "Epoch 7/10, Loss: 0.0000, Accuracy: 0.9767, Precision: 0.9766, Recall: 0.9765, F1 Score: 0.9766\n",
            "Confusion Matrix:\n",
            "[[5859    2    9    4    3    8    9    2   17   10]\n",
            " [   1 6667   12    7   10    1    4   14   17    9]\n",
            " [  15   18 5821   31    5    2   11   24   27    4]\n",
            " [   4   12   50 5921    0   49    3   20   47   25]\n",
            " [   4   10   11    3 5707    2   14    7    7   77]\n",
            " [  10    2    3   47    3 5279   23    1   36   17]\n",
            " [  24    4    9    1   12   19 5833    0   15    1]\n",
            " [   2   13   25   15   12    1    0 6143   14   40]\n",
            " [  11   20   28   48   13   32   15   11 5639   34]\n",
            " [   9    4    6   35   64   19    1   48   28 5735]]\n",
            "Epoch 8/10, Loss: 0.0000, Accuracy: 0.9786, Precision: 0.9784, Recall: 0.9784, F1 Score: 0.9784\n",
            "Confusion Matrix:\n",
            "[[5851    1   10    1    6   14   15    2   17    6]\n",
            " [   2 6681   13    8    4    1    1   11   17    4]\n",
            " [  17    9 5833   23    8    5   11   20   26    6]\n",
            " [   7    7   34 5942    3   46    2   15   50   25]\n",
            " [   4    6    7    1 5717    3   11   11   11   71]\n",
            " [  10    3    5   43    6 5283   25    1   24   21]\n",
            " [  18    2    5    1   12   19 5842    2   16    1]\n",
            " [   2    8   18   11   11    4    1 6149    6   55]\n",
            " [   9   18   21   48    8   20   18    9 5673   27]\n",
            " [   5    4    3   28   66   18    2   50   29 5744]]\n",
            "Epoch 9/10, Loss: 0.0000, Accuracy: 0.9816, Precision: 0.9815, Recall: 0.9815, F1 Score: 0.9815\n",
            "Confusion Matrix:\n",
            "[[5869    1    5    2    7    8   10    2   14    5]\n",
            " [   0 6687    9    8    4    2    2    9   15    6]\n",
            " [  15    7 5863   22    3    1    3   23   18    3]\n",
            " [   3   10   29 5968    1   43    1   12   41   23]\n",
            " [   4    6    5    1 5732    0   11    9   10   64]\n",
            " [   7    1    3   48    5 5302   17    1   23   14]\n",
            " [  17    2    8    0   10   18 5851    0   12    0]\n",
            " [   4    7   23   15   10    2    0 6162    7   35]\n",
            " [  15   15   21   31    5   17   19    9 5688   31]\n",
            " [   3    3    6   24   57   16    1   43   21 5775]]\n",
            "Epoch 10/10, Loss: 0.0000, Accuracy: 0.9840, Precision: 0.9839, Recall: 0.9839, F1 Score: 0.9839\n",
            "Confusion Matrix:\n",
            "[[5873    1    7    1    2    4   16    1   16    2]\n",
            " [   0 6700    9    5    2    0    2    6   14    4]\n",
            " [  13    9 5848   25    6    2    8   21   19    7]\n",
            " [   3    3   37 5987    1   31    0   12   38   19]\n",
            " [   2    5    6    2 5755    1    6    7    6   52]\n",
            " [   5    3    3   33    4 5326   18    2   14   13]\n",
            " [  18    2    7    0    7   14 5859    0   10    1]\n",
            " [   2    8   18    7    8    0    1 6177    5   39]\n",
            " [   6   15   19   34    6   16   17    1 5716   21]\n",
            " [   4    3    1   21   46   12    0   35   26 5801]]\n",
            "\n",
            "Test Accuracy: 0.9582\n",
            "Test Precision: 0.9586, Test Recall: 0.9581, Test F1 Score: 0.9578\n",
            "Test Confusion Matrix:\n",
            "[[ 959    0    1    1    1    9    2    0    2    5]\n",
            " [   0 1122    3    0    2    1    1    1    5    0]\n",
            " [   7    4  993    5    6    2    1    6    7    1]\n",
            " [   0    2    3  958    1   26    0    4    5   11]\n",
            " [   1    0    3    0  951    2    2    1    2   20]\n",
            " [   1    0    0    4    1  878    3    0    1    4]\n",
            " [   5    4    3    0   22   25  895    0    4    0]\n",
            " [   2   13    8    6   16    4    1  940    0   38]\n",
            " [   5    3    5   12    2   24    1    0  910   12]\n",
            " [   1    3    0    4   13    5    1    2    4  976]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SAVING AND LOADING MODEL"
      ],
      "metadata": {
        "id": "yaMSnyxfNm-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez('my_model.npz',\n",
        "         input_layer=input_layer,\n",
        "         weights_input_hidden=weights_input_hidden,\n",
        "         biases_hidden=biases_hidden,\n",
        "         weights_hidden_output=weights_hidden_output,\n",
        "         biases_output=biases_output)"
      ],
      "metadata": {
        "id": "t5EdC9Ke-gWK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load weights and biases\n",
        "loaded_model = np.load('/content/my_model.npz')\n",
        "weights_input_hidden = loaded_model['weights_input_hidden']\n",
        "biases_hidden = loaded_model['biases_hidden']\n",
        "weights_hidden_output = loaded_model['weights_hidden_output']\n",
        "biases_output = loaded_model['biases_output']"
      ],
      "metadata": {
        "id": "iIhAODfLAuBb"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREDICTION\n"
      ],
      "metadata": {
        "id": "qq6ItHRn18y3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TAKING INPUT IMAGE"
      ],
      "metadata": {
        "id": "YJHVgaqjN7iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the image in grayscale\n",
        "image = cv2.imread('/content/1.PNG', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Apply adaptive thresholding to separate the digit from the background\n",
        "_, thresh_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "# Invert the image colors\n",
        "inverted_image = 255 - thresh_image\n",
        "\n",
        "# Resize the inverted image to 28x28\n",
        "resized_image = cv2.resize(inverted_image, (28, 28))\n",
        "\n",
        "# Normalize the resized image\n",
        "normalized_image = resized_image / 255.0\n",
        "\n",
        "# Invert the image colors again (from white to black and black to white)\n",
        "final_image = 1 - normalized_image\n",
        "\n",
        "# Flatten the image\n",
        "flattened_image = final_image.reshape(1, -1)\n",
        "\n",
        "# Display the original and processed images\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "# Original image\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title('Original Image')\n",
        "plt.axis('off')\n",
        "\n",
        "# Processed image\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(final_image, cmap='gray')\n",
        "plt.title('Processed Image (Inverted)')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "collapsed": true,
        "id": "qgNnQy7LA-lx",
        "outputId": "8fb73e42-cbba-4845-c15e-377af163db84"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PREDICTIONG RESULT"
      ],
      "metadata": {
        "id": "EMkpqGeEODyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer = flattened_image\n",
        "hidden_layer_input = np.dot(input_layer, weights_input_hidden) + biases_hidden\n",
        "hidden_layer_output = 1 / (1 + np.exp(-hidden_layer_input))  # Sigmoid activation\n",
        "output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + biases_output\n",
        "output_layer_output = softmax(output_layer_input)\n",
        "prediction = np.argmax(output_layer_output)\n",
        "\n",
        "print(prediction)"
      ],
      "metadata": {
        "id": "uxc57SCGuSSx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf8002d7-6834-40dd-d3bd-1fe5630df525"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    }
  ]
}