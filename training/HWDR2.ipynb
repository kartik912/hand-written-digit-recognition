{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5690,"status":"ok","timestamp":1697555671067,"user":{"displayName":"Kartik Yadav","userId":"01109628832264741342"},"user_tz":-330},"id":"3LBoovNqK8db","outputId":"c5dba741-c1e5-4f9f-810b-5ebfb2e55260"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5013,"status":"ok","timestamp":1697555676076,"user":{"displayName":"Kartik Yadav","userId":"01109628832264741342"},"user_tz":-330},"id":"esSTrtHt76fR","outputId":"508f0509-bf43-4871-c98e-219d87612f5e"},"outputs":[],"source":["# !pip install mnist scikit-learn opencv-python tensorflow"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZurPwp9s_CvU"},"outputs":[],"source":["import numpy as np\n","import mnist\n","from sklearn.model_selection import train_test_split\n","import cv2\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# import tensorflow as tf\n","\n","# # Load the MNIST dataset\n","# mnist = tf.keras.datasets.mnist\n","# (train_images, train_labels), (test_images, test_labels) = mnist.load_data()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# train_images = train_images / 255.0\n","# test_images = test_images / 255.0\n","\n","# Reshape the images to add a color channel dimension\n","# train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n","# test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1298,"status":"ok","timestamp":1697555677368,"user":{"displayName":"Kartik Yadav","userId":"01109628832264741342"},"user_tz":-330},"id":"TO7yYbeo_HFB","outputId":"51f281f6-42b4-44ac-8c95-d6443851aade"},"outputs":[],"source":["# Load the MNIST dataset\n","# train_images = mnist.train_images()\n","# train_labels = mnist.train_labels()\n","# test_images = mnist.test_images()\n","# test_labels = mnist.test_labels()\n","\n","# Flatten and normalize the images\n","# train_images = train_images.reshape(-1, 28*28) / 255.0\n","# test_images = test_images.reshape(-1, 28*28) / 255.0\n","# print(train_images[0])\n","# One-hot encode the labels\n","# num_classes = 10\n","# train_labels = np.eye(num_classes)[train_labels]\n","# test_labels = np.eye(num_classes)[test_labels]"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# datagen = ImageDataGenerator(\n","#     rotation_range=10,        # Randomly rotate images in the range (degrees, 0 to 180)\n","#     width_shift_range=0.1,    # Randomly shift images horizontally (fraction of total width)\n","#     height_shift_range=0.1,   # Randomly shift images vertically (fraction of total height)\n","#     zoom_range=0.1,           # Randomly zoom images\n","#     shear_range=0.1           # Randomly shear images\n","# )\n","\n","# # Fit the data generator on the training images\n","# datagen.fit(train_images)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# train_labels = train_labels.astype(int)\n","# test_labels = test_labels.astype(int)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":360004,"status":"ok","timestamp":1697556037367,"user":{"displayName":"Kartik Yadav","userId":"01109628832264741342"},"user_tz":-330},"id":"XpI5rlYX7j9W","outputId":"b6818cbc-15f2-4058-c8cf-82ae717d191e"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[18], line 64\u001b[0m\n\u001b[0;32m     61\u001b[0m total_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     62\u001b[0m num_batches \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_images) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m batch_size\n\u001b[1;32m---> 64\u001b[0m \u001b[39mfor\u001b[39;00m X_batch, y_batch \u001b[39min\u001b[39;00m datagen\u001b[39m.\u001b[39mflow(train_images, train_labels_one_hot, batch_size\u001b[39m=\u001b[39mbatch_size):\n\u001b[0;32m     65\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X_batch)):\n\u001b[0;32m     66\u001b[0m         \u001b[39m# Forward pass\u001b[39;00m\n\u001b[0;32m     67\u001b[0m         input_layer \u001b[39m=\u001b[39m X_batch[i]\u001b[39m.\u001b[39mflatten()  \u001b[39m# Flatten the input image\u001b[39;00m\n","File \u001b[1;32md:\\Projects\\hand-digit-fullstack\\myenv\\lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:112\u001b[0m, in \u001b[0;36mIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m     index_array \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_generator)\n\u001b[0;32m    110\u001b[0m \u001b[39m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[39m# so it can be done in parallel\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_batches_of_transformed_samples(index_array)\n","File \u001b[1;32md:\\Projects\\hand-digit-fullstack\\myenv\\lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:654\u001b[0m, in \u001b[0;36mNumpyArrayIterator._get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    652\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx[j]\n\u001b[0;32m    653\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_data_generator\u001b[39m.\u001b[39mget_random_transform(x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m--> 654\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimage_data_generator\u001b[39m.\u001b[39;49mapply_transform(\n\u001b[0;32m    655\u001b[0m     x\u001b[39m.\u001b[39;49mastype(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype), params\n\u001b[0;32m    656\u001b[0m )\n\u001b[0;32m    657\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_data_generator\u001b[39m.\u001b[39mstandardize(x)\n\u001b[0;32m    658\u001b[0m batch_x[i] \u001b[39m=\u001b[39m x\n","File \u001b[1;32md:\\Projects\\hand-digit-fullstack\\myenv\\lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1413\u001b[0m, in \u001b[0;36mImageDataGenerator.apply_transform\u001b[1;34m(self, x, transform_parameters)\u001b[0m\n\u001b[0;32m   1410\u001b[0m img_col_axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol_axis \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1411\u001b[0m img_channel_axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchannel_axis \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1413\u001b[0m x \u001b[39m=\u001b[39m apply_affine_transform(\n\u001b[0;32m   1414\u001b[0m     x,\n\u001b[0;32m   1415\u001b[0m     transform_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtheta\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m),\n\u001b[0;32m   1416\u001b[0m     transform_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtx\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m),\n\u001b[0;32m   1417\u001b[0m     transform_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mty\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m),\n\u001b[0;32m   1418\u001b[0m     transform_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mshear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m),\n\u001b[0;32m   1419\u001b[0m     transform_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mzx\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m1\u001b[39;49m),\n\u001b[0;32m   1420\u001b[0m     transform_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mzy\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m1\u001b[39;49m),\n\u001b[0;32m   1421\u001b[0m     row_axis\u001b[39m=\u001b[39;49mimg_row_axis,\n\u001b[0;32m   1422\u001b[0m     col_axis\u001b[39m=\u001b[39;49mimg_col_axis,\n\u001b[0;32m   1423\u001b[0m     channel_axis\u001b[39m=\u001b[39;49mimg_channel_axis,\n\u001b[0;32m   1424\u001b[0m     fill_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfill_mode,\n\u001b[0;32m   1425\u001b[0m     cval\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcval,\n\u001b[0;32m   1426\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpolation_order,\n\u001b[0;32m   1427\u001b[0m )\n\u001b[0;32m   1429\u001b[0m \u001b[39mif\u001b[39;00m transform_parameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mchannel_shift_intensity\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m     x \u001b[39m=\u001b[39m apply_channel_shift(\n\u001b[0;32m   1431\u001b[0m         x,\n\u001b[0;32m   1432\u001b[0m         transform_parameters[\u001b[39m\"\u001b[39m\u001b[39mchannel_shift_intensity\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   1433\u001b[0m         img_channel_axis,\n\u001b[0;32m   1434\u001b[0m     )\n","File \u001b[1;32md:\\Projects\\hand-digit-fullstack\\myenv\\lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1879\u001b[0m, in \u001b[0;36mapply_affine_transform\u001b[1;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[0;32m   1876\u001b[0m final_affine_matrix \u001b[39m=\u001b[39m transform_matrix[:\u001b[39m2\u001b[39m, :\u001b[39m2\u001b[39m]\n\u001b[0;32m   1877\u001b[0m final_offset \u001b[39m=\u001b[39m transform_matrix[:\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m]\n\u001b[1;32m-> 1879\u001b[0m channel_images \u001b[39m=\u001b[39m [\n\u001b[0;32m   1880\u001b[0m     scipy\u001b[39m.\u001b[39mndimage\u001b[39m.\u001b[39minterpolation\u001b[39m.\u001b[39maffine_transform(\n\u001b[0;32m   1881\u001b[0m         x_channel,\n\u001b[0;32m   1882\u001b[0m         final_affine_matrix,\n\u001b[0;32m   1883\u001b[0m         final_offset,\n\u001b[0;32m   1884\u001b[0m         order\u001b[39m=\u001b[39morder,\n\u001b[0;32m   1885\u001b[0m         mode\u001b[39m=\u001b[39mfill_mode,\n\u001b[0;32m   1886\u001b[0m         cval\u001b[39m=\u001b[39mcval,\n\u001b[0;32m   1887\u001b[0m     )\n\u001b[0;32m   1888\u001b[0m     \u001b[39mfor\u001b[39;00m x_channel \u001b[39min\u001b[39;00m x\n\u001b[0;32m   1889\u001b[0m ]\n\u001b[0;32m   1890\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack(channel_images, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m   1891\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrollaxis(x, \u001b[39m0\u001b[39m, channel_axis \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n","File \u001b[1;32md:\\Projects\\hand-digit-fullstack\\myenv\\lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1880\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1876\u001b[0m final_affine_matrix \u001b[39m=\u001b[39m transform_matrix[:\u001b[39m2\u001b[39m, :\u001b[39m2\u001b[39m]\n\u001b[0;32m   1877\u001b[0m final_offset \u001b[39m=\u001b[39m transform_matrix[:\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m]\n\u001b[0;32m   1879\u001b[0m channel_images \u001b[39m=\u001b[39m [\n\u001b[1;32m-> 1880\u001b[0m     scipy\u001b[39m.\u001b[39;49mndimage\u001b[39m.\u001b[39;49minterpolation\u001b[39m.\u001b[39;49maffine_transform(\n\u001b[0;32m   1881\u001b[0m         x_channel,\n\u001b[0;32m   1882\u001b[0m         final_affine_matrix,\n\u001b[0;32m   1883\u001b[0m         final_offset,\n\u001b[0;32m   1884\u001b[0m         order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1885\u001b[0m         mode\u001b[39m=\u001b[39;49mfill_mode,\n\u001b[0;32m   1886\u001b[0m         cval\u001b[39m=\u001b[39;49mcval,\n\u001b[0;32m   1887\u001b[0m     )\n\u001b[0;32m   1888\u001b[0m     \u001b[39mfor\u001b[39;00m x_channel \u001b[39min\u001b[39;00m x\n\u001b[0;32m   1889\u001b[0m ]\n\u001b[0;32m   1890\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack(channel_images, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m   1891\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrollaxis(x, \u001b[39m0\u001b[39m, channel_axis \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n","File \u001b[1;32md:\\Projects\\hand-digit-fullstack\\myenv\\lib\\site-packages\\scipy\\ndimage\\_interpolation.py:626\u001b[0m, in \u001b[0;36maffine_transform\u001b[1;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[0;32m    623\u001b[0m     _nd_image\u001b[39m.\u001b[39mzoom_shift(filtered, matrix, offset\u001b[39m/\u001b[39mmatrix, output, order,\n\u001b[0;32m    624\u001b[0m                          mode, cval, npad, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    625\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 626\u001b[0m     _nd_image\u001b[39m.\u001b[39;49mgeometric_transform(filtered, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, matrix, offset,\n\u001b[0;32m    627\u001b[0m                                   output, order, mode, cval, npad, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    628\u001b[0m                                   \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    629\u001b[0m \u001b[39mreturn\u001b[39;00m output\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import numpy as np\n","import tensorflow as tf\n","\n","# Load the MNIST dataset\n","mnist = tf.keras.datasets.mnist\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","# Normalize the images to the range [0, 1]\n","train_images = train_images / 255.0\n","test_images = test_images / 255.0\n","\n","# Reshape the images to add a color channel dimension\n","train_images = train_images.reshape((train_images.shape[0], 28, 28, 1))\n","test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))\n","\n","# Ensure labels are integers\n","train_labels = train_labels.astype(int)\n","test_labels = test_labels.astype(int)\n","\n","# One-hot encode labels\n","def one_hot_encode(labels, num_classes):\n","    return np.eye(num_classes)[labels]\n","\n","train_labels_one_hot = one_hot_encode(train_labels, 10)\n","test_labels_one_hot = one_hot_encode(test_labels, 10)\n","\n","# Data augmentation\n","datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    shear_range=0.1,\n","    zoom_range=0.1\n",")\n","\n","datagen.fit(train_images)\n","\n","# Define a simple feedforward neural network\n","input_size = 28 * 28\n","hidden_size = 128\n","output_size = 10\n","learning_rate = 0.1\n","\n","# Initialize weights and biases\n","np.random.seed(0)\n","weights_input_hidden = np.random.randn(input_size, hidden_size)\n","biases_hidden = np.zeros(hidden_size)\n","weights_hidden_output = np.random.randn(hidden_size, output_size)\n","biases_output = np.zeros(output_size)\n","\n","# Softmax function\n","def softmax(x):\n","    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))  # Subtract the max for numerical stability\n","    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n","\n","# Training loop\n","num_epochs = 10\n","batch_size = 32\n","\n","for epoch in range(num_epochs):\n","    total_loss = 0\n","    num_batches = len(train_images) // batch_size\n","\n","    for X_batch, y_batch in datagen.flow(train_images, train_labels_one_hot, batch_size=batch_size):\n","        for i in range(len(X_batch)):\n","            # Forward pass\n","            input_layer = X_batch[i].flatten()  # Flatten the input image\n","            hidden_layer_input = np.dot(input_layer, weights_input_hidden) + biases_hidden\n","            hidden_layer_output = 1 / (1 + np.exp(-hidden_layer_input))  # Sigmoid activation\n","            output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + biases_output\n","            output_layer_output = softmax(output_layer_input)\n","\n","            # Calculate loss (cross-entropy)\n","            loss = -np.sum(y_batch[i] * np.log(output_layer_output))\n","            total_loss += loss\n","\n","            # Backpropagation\n","            output_error = output_layer_output - y_batch[i]\n","            hidden_error = np.dot(output_error, weights_hidden_output.T)\n","            hidden_delta = hidden_error * hidden_layer_output * (1 - hidden_layer_output)\n","            \n","            weights_hidden_output -= learning_rate * np.outer(hidden_layer_output, output_error)\n","            biases_output -= learning_rate * output_error\n","            weights_input_hidden -= learning_rate * np.outer(input_layer, hidden_delta)\n","            biases_hidden -= learning_rate * hidden_delta\n","        \n","        if len(X_batch) < batch_size:\n","            break  # To avoid processing incomplete batch at the end\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / num_batches}\")\n","\n","# Testing\n","correct = 0\n","for i in range(len(test_images)):\n","    input_layer = test_images[i].flatten()  # Flatten the input image\n","    hidden_layer_input = np.dot(input_layer, weights_input_hidden) + biases_hidden\n","    hidden_layer_output = 1 / (1 + np.exp(-hidden_layer_input))  # Sigmoid activation\n","    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + biases_output\n","    output_layer_output = softmax(output_layer_input)\n","    prediction = np.argmax(output_layer_output)\n","    if prediction == np.argmax(test_labels_one_hot[i]):\n","        correct += 1\n","\n","accuracy = correct / len(test_images) * 100\n","print(f\"Test Accuracy: {accuracy:.2f}%\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O6D4PqGLKwXk"},"outputs":[],"source":["image = cv2.imread('/content/drive/MyDrive/hand digit digit recog/input image/six.PNG', cv2.IMREAD_GRAYSCALE)\n","resized_image = cv2.resize(image, (28, 28))\n","normalized_image = resized_image / 255.0\n","\n","# input_image = image.reshape(-1, 28*28) / 255.0\n","flattened_image = normalized_image.reshape(1, -1)\n","flattened_image[flattened_image >= 1] = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1697556885773,"user":{"displayName":"Kartik Yadav","userId":"01109628832264741342"},"user_tz":-330},"id":"PbIUYIDx73Y0","outputId":"5c974d51-8ecb-4ef0-8500-5b8e27811e6c"},"outputs":[{"name":"stdout","output_type":"stream","text":["5\n"]}],"source":["input_layer = flattened_image\n","hidden_layer_input = np.dot(input_layer, weights_input_hidden) + biases_hidden\n","hidden_layer_output = 1 / (1 + np.exp(-hidden_layer_input))  # Sigmoid activation\n","output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + biases_output\n","output_layer_output = softmax(output_layer_input)\n","prediction = np.argmax(output_layer_output)\n","\n","print(prediction)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uBVczSxiRTSL"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
